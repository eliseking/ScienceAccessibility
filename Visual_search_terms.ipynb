{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install git+\"https://github.com/russelljjarvis/textstat.git\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#TkAgg\n",
    "import matplotlib\n",
    "#matplotlib.use('Qt5Agg')\n",
    "matplotlib.use('agg')\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#matplotlib.use('QT4Agg')\n",
    "#!pip install wxPython\n",
    "#!pip install backend_wx\n",
    "\n",
    "#WX\n",
    "#QTAgg\n",
    "#QT4Agg\n",
    "\n",
    "try: \n",
    "    with open('unraveled_links.p','rb') as handle:\n",
    "        unravel = pickle.load(handle)\n",
    "\n",
    "except:\n",
    "    import dask.bag as db\n",
    "    from t_analysis_flat import web_iter, map_wrapper\n",
    "    grid = {}\n",
    "    grid['b']=[0,1,2,3]\n",
    "    query_list = ['GMO','Genetically_Modified_Organism','Transgenic','Vaccine']\n",
    "    grid['search_term'] = [ (i, q) for i,q in enumerate(query_list) ]\n",
    "    from sklearn.grid_search import ParameterGrid\n",
    "    grid = list(ParameterGrid(grid))\n",
    "    grid = [(dicti['search_term'][0],dicti['search_term'][1],dicti['b']) for dicti in grid ]\n",
    "    #from dask.distributed import Client\n",
    "    import dask.bag as db\n",
    "    grid = db.from_sequence(grid,npartitions = 8)\n",
    "    list_per_links = list(db.map(web_iter,grid).compute())\n",
    "    \n",
    "    remove_empty = [i for i in list_per_links if len(i)>0 ]\n",
    "    unravel = []\n",
    "    for i in remove_empty:\n",
    "        unravel.extend(i)\n",
    "    \n",
    "    with open('unraveled_links.p','wb') as handle:\n",
    "        pickle.dump(unravel,handle)\n",
    "    #with open('unraveled_links.p','rb') as handle:\n",
    "    #    assert handle\n",
    "    #    unravel = pickle.load(handle)\n",
    "        \n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cliau': 24.17,\n",
       " 'dcr': 8.56,\n",
       " 'dw': 1382,\n",
       " 'fkg': 12.9,\n",
       " 'fre': 24.85,\n",
       " 'gf': 17.930464933018126,\n",
       " 'keyword': 'GMO',\n",
       " 'link_rank': 0,\n",
       " 'lwf': 4.583333333333333,\n",
       " 'ri': 19.2,\n",
       " 'se': 'google_',\n",
       " 'sentcount': 188,\n",
       " 'smog': 10.3,\n",
       " 'sp': 0.055084360084360046,\n",
       " 'ss': 0.4824196482529815,\n",
       " 'standard': '12th and 13th grade',\n",
       " 'stfreq': 161,\n",
       " 'wcount': 5076}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unravel[0]['urlDat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(list_per_links[1])\\\n",
    "\n",
    "bings = [ f for f in unravel if f['urlDat']['se'] =='bing_']\n",
    "#print(bings)\n",
    "googles = [ f for f in unravel if f['urlDat']['se'] =='google_']\n",
    "GMOs = [ f for f in unravel if f['urlDat']['keyword'] =='GMO']\n",
    "GMO_standard = [ f['urlDat']['standard'] for f in unravel if f['urlDat']['keyword'] =='GMO' ]\n",
    "GMO_rank = [ f['urlDat']['link_rank'] for f in unravel if f['urlDat']['keyword'] =='GMO' ]\n",
    "\n",
    "GMO_subjectivity_pol = [ f['urlDat']['sp'] for f in unravel if f['urlDat']['keyword'] =='GMO' ]\n",
    "GMO_subjectivity_sent = [ f['urlDat']['ss'] for f in unravel if f['urlDat']['keyword'] =='GMO' ]\n",
    "\n",
    "GMO_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 google_\n",
      "1 gScholar_\n",
      "2 bing_\n",
      "3 yahoo_\n",
      "0 0\n",
      "0 google_\n",
      "1 gScholar_\n",
      "2 bing_\n",
      "3 yahoo_\n",
      "0 0\n",
      "0 google_\n",
      "1 gScholar_\n",
      "2 bing_\n",
      "3 yahoo_\n",
      "0 0\n",
      "0 google_\n",
      "1 gScholar_\n",
      "2 bing_\n",
      "3 yahoo_\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "se = {}\n",
    "se[0] = 'google_'\n",
    "se[1] = 'gScholar_'\n",
    "se[2] = 'bing_'\n",
    "se[3] = 'yahoo_'\n",
    "\n",
    "ses = list(se.values())\n",
    "search_query = str('Vaccine')\n",
    "searchList = ['GMO','Genetically_Modified_Organism','Transgenic','Vaccine']\n",
    "\n",
    "for outer,search_query in enumerate(searchList):    \n",
    "    x = []\n",
    "    y = []\n",
    "    for i,v in enumerate(ses):\n",
    "        print(i,v)\n",
    "        complexity = [ f['urlDat']['fkg'] for f in unravel if f['urlDat']['keyword'] ==search_query and f['urlDat']['se'] == v ]\n",
    "        rank = [ f['urlDat']['link_rank'] for f in unravel if f['urlDat']['keyword'] ==search_query and f['urlDat']['se'] == v ]\n",
    "        #print(complexity[0][0],complexity[0][0])\n",
    "        x.append(rank)\n",
    "        y.append(complexity)\n",
    "    print(len(complexity),len(rank))\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(str('reading grade ')+search_query)\n",
    "    plt.ylabel('text reading level')\n",
    "    plt.xlabel('link rank')\n",
    "    plt.scatter(x[0],y[0],label=ses[0])\n",
    "    plt.scatter(x[1],y[1],label=ses[1])\n",
    "    plt.scatter(x[2],y[2],label=ses[2])\n",
    "    plt.scatter(x[3],y[3],label=ses[3])\n",
    "    \n",
    "    #labels = [ses[0],ses[1],ses[2],ses[3]]\n",
    "    #lineObjects = plt.plot(x[0],y[0],'r',x[1],y[1],'g',x[2],y[2],'b',x[3],y[3],'k')\n",
    "    #plt.legend(lineObjects,labels)\n",
    "    legend = ax.legend(loc='upper center', shadow=True)\n",
    "    plt.savefig('rank_versus_complexity_{0}.png'.format(search_query))\n",
    "    plt.clf()\n",
    "import textstat\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.       Pro/anti/neutral vs. text complexity#\n",
    "\n",
    "for outer,search_query in enumerate(searchList):    \n",
    "    x = []\n",
    "    y = []\n",
    "    for i,v in enumerate(ses):\n",
    "        #print(i,v)\n",
    "        complexity = [ f['urlDat']['fkg'] for f in unravel if f['urlDat']['keyword'] ==search_query and f['urlDat']['se'] == v ]\n",
    "        sent = [ f['urlDat']['sp'] for f in unravel if f['urlDat']['keyword'] ==search_query and f['urlDat']['se'] == v ]\n",
    "        #print(complexity[0][0],complexity[0][0])\n",
    "        x.append(sent)\n",
    "        y.append(complexity)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(str('sentiment ')+search_query)\n",
    "    plt.ylabel('text reading level')\n",
    "    plt.xlabel('sentiment polarity')\n",
    "    labels = [ses[0],ses[1],ses[2],ses[3]]\n",
    "    #lineObjects = \n",
    "    plt.scatter(x[0],y[0],label=ses[0])\n",
    "    plt.scatter(x[1],y[1],label=ses[1])\n",
    "    plt.scatter(x[2],y[2],label=ses[2])\n",
    "    plt.scatter(x[3],y[3],label=ses[3])\n",
    "\n",
    "    legend = ax.legend(loc='upper center', shadow=True)\n",
    "    plt.savefig('sentiment_vs_complexity{0}.png'.format(search_query))\n",
    "    plt.clf()\n",
    "import textstat\n",
    "import numpy as np\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "# 3.       GMO/transgenics vs. text complexity\n",
    "\n",
    "import seaborn as sns\n",
    "se = {}\n",
    "se[0] = 'google_'\n",
    "se[1] = 'gScholar_'\n",
    "se[2] = 'bing_'\n",
    "se[3] = 'yahoo_'\n",
    "\n",
    "ses = list(se.values())\n",
    "search_query = str('Vaccine')\n",
    "search_query = ['GMO','Transgenic']\n",
    "xx=[]\n",
    "yy=[]\n",
    "for outer,sq in enumerate(search_query):    \n",
    "    x = []\n",
    "    y = []\n",
    "    for i,v in enumerate(ses):\n",
    "        complexity = [ f['urlDat']['fkg'] for f in unravel if f['urlDat']['keyword'] ==sq and f['urlDat']['se'] == v and f['urlDat']['link_rank'] == 0 ]\n",
    "        if len(complexity)>0:\n",
    "            comp = float(complexity[0])\n",
    "        else:\n",
    "            comp = 0\n",
    "        xx.append(i)\n",
    "        y.append(comp)    \n",
    "    yy.append(y)\n",
    "print(len(complexity),len(rank))\n",
    "fig, ax = plt.subplots()\n",
    "# Two subplots, the axes array is 1-d\n",
    "width = 0.35       # the width of the bars\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#f, axarr = plt.subplots(1, sharex=True)\n",
    "ind = [i for i,v in enumerate(ses)]\n",
    "offset = [(i+width)/2.0 for i,v in enumerate(ses)]\n",
    "\n",
    "rects1 = ax.bar(ind,yy[0],width, color='r')# yerr=men_std)\n",
    "rects2 = ax.bar(ind, yy[1], width, color='y')#, yerr=women_std)\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Complexity')\n",
    "ax.set_title('Complexity by search query and Search Engine')\n",
    "ax.set_xticks(offset)\n",
    "ax.set_xticklabels((se[0], se[1], se[2], se[3]))#, 'G5'))\n",
    "\n",
    "ax.legend((rects1[0], rects2[0]), ('GMO', 'Transgenic'))\n",
    "\n",
    "plt.savefig('GMO_Transgenic_complexity_{0}{1}.png'.format(search_query[0],search_query[1]))\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "se = {}\n",
    "se[0] = 'google_'\n",
    "se[1] = 'gScholar_'\n",
    "se[2] = 'bing_'\n",
    "se[3] = 'yahoo_'\n",
    "\n",
    "ses = list(se.values())\n",
    "search_query = str('Vaccine')\n",
    "search_query = ['GMO','Transgenic']\n",
    "xx=[]\n",
    "yy=[]\n",
    "for outer,sq in enumerate(search_query):    \n",
    "    x = []\n",
    "    y = []\n",
    "    for i,v in enumerate(ses):\n",
    "        complexity = [ f['urlDat']['fkg'] for f in unravel if f['urlDat']['keyword'] ==sq and f['urlDat']['se'] == v and f['urlDat']['link_rank'] == 0 ]\n",
    "        #complexity = [ f['urlDat']['fkg'] for f in unravel if f['urlDat']['keyword'] ==sq and f['urlDat']['se'] == v and f['urlDat']['link_rank'] == 0 ]\n",
    "        sent = [ f['urlDat']['sp'] for f in unravel if f['urlDat']['keyword'] == sq and f['urlDat']['se'] == v and f['urlDat']['link_rank'] == 0 ]\n",
    "        if len(complexity)>0:\n",
    "            comp = float(complexity[0])\n",
    "        else:\n",
    "            comp = 0\n",
    "        if len(sent)>0:\n",
    "            sent = float(sent[0])\n",
    "        else:\n",
    "            sent = 0\n",
    "    \n",
    "        xx.append(i)\n",
    "        y.append((comp,sent))    \n",
    "    yy.append(y)\n",
    "print(len(complexity),len(rank))\n",
    "fig, ax = plt.subplots()\n",
    "# Two subplots, the axes array is 1-d\n",
    "width = 0.35       # the width of the bars\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#f, axarr = plt.subplots(1, sharex=True)\n",
    "ind = [i for i,v in enumerate(ses)]\n",
    "offset = [(i+width)/2.0 for i,v in enumerate(ses)]\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.title(str('sentiment '))#+search_query)\n",
    "plt.ylabel('text reading level')\n",
    "plt.xlabel('sentiment polarity')\n",
    "#lineObjects = \n",
    "sentt0 = [sent[1] for sent in yy[0] ]\n",
    "complexity0 = [sent[0] for sent in yy[0] ]\n",
    "plt.scatter(sentt0,complexity0,label='GMO')\n",
    "sentt1 = [sent[1] for sent in yy[1] ]\n",
    "complexity1 = [sent[0] for sent in yy[0] ]\n",
    "plt.scatter(sentt1,complexity1,label='Transgenic')\n",
    "\n",
    "\n",
    "#    plt.scatter(x[0],y[0],label=ses[0])\n",
    "#    plt.scatter(x[1],y[1],label=ses[1])\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True)\n",
    "#ax.set_xticks(offset)\n",
    "#ax.set_xticklabels((se[0], se[1], se[2], se[3]))#, 'G5'))\n",
    "\n",
    "#plt.savefig('sentiment_vs_complexity{0}.png'.format(search_query))\n",
    "#plt.clf()\n",
    "\n",
    "\n",
    "plt.savefig('Figure2{0}{1}.png'.format(search_query[0],search_query[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
