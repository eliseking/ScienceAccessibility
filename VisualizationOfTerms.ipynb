{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe directory '/Users/rjjarvis/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/Users/rjjarvis/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: nltk in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages\n",
      "Requirement already satisfied: matplotlib in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages\n",
      "Requirement already satisfied: six in /usr/local/Cellar/ipython@5/5.5.0_2/libexec/vendor/lib/python2.7/site-packages (from nltk)\n",
      "Requirement already satisfied: functools32 in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from matplotlib)\n",
      "Requirement already satisfied: subprocess32 in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from matplotlib)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from matplotlib)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/Cellar/ipython@5/5.5.0_2/libexec/vendor/lib/python2.7/site-packages (from matplotlib)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from matplotlib)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from matplotlib)\n",
      "Requirement already satisfied: pytz in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from matplotlib)\n",
      "\u001b[33mThe directory '/Users/rjjarvis/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/Users/rjjarvis/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.0.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (16.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 16.8MB 87kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tabulate in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages\n",
      "Collecting glob\n",
      "\u001b[31m  Could not find a version that satisfies the requirement glob (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for glob\u001b[0m\n",
      "\u001b[33mThe directory '/Users/rjjarvis/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/Users/rjjarvis/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: textstat in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages\n",
      "Requirement already satisfied: repoze.lru in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from textstat)\n",
      "Requirement already satisfied: pyphen in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from textstat)\n",
      "\u001b[33mThe directory '/Users/rjjarvis/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/Users/rjjarvis/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: tabulate in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages\n",
      "Requirement already satisfied: textblob in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from textblob)\n",
      "Requirement already satisfied: six in /usr/local/Cellar/ipython@5/5.5.0_2/libexec/vendor/lib/python2.7/site-packages (from nltk>=3.1->textblob)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "!pip install nltk matplotlib\n",
    "!pip install bs4 scipy tabulate glob dask textstat json glob distributed\n",
    "!pip install textstat\n",
    "!pip install tabulate textblob\n",
    "\n",
    "#import matplotlib\n",
    "#%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#general python imports\n",
    "import os\n",
    "#import dask\n",
    "import matplotlib # Its not that this file is responsible for doing plotting, but it calls many modules that are, such that it needs to pre-empt\n",
    "# setting of an appropriate backend.\n",
    "#matplotlib.use('Agg')\n",
    "import sys\n",
    "import numpy\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import math\n",
    "import re\n",
    "#import requests\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "from textblob import TextBlob\n",
    "import glob\n",
    "\n",
    "#text analysis imports\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "tagger = PerceptronTagger(load=False)\n",
    "\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.corpus import cmudict\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk import compat\n",
    "#from nltk.compat import Counter\n",
    "#from nltk.draw import dispersion_plot\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "from textstat.textstat import textstat\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "# Set user parameters based on type of analysis\n",
    "searchList = ['GMO','Genetically_Modified_Organism','Transgenic','Vaccine']\n",
    "nweb = 2 #number of search websites being implemented (google, google scholar, bing, yahoo)\n",
    "numURLs = 10 #number of URLs per search website  (number determined by 1.scrape code)\n",
    "\n",
    "#also save these parameters for analysis purposes\n",
    "spec_dict = { 'searchList':searchList, 'nweb':nweb, 'numURLs':numURLs}\n",
    "handle = 'Data/analysisSpecs.mat'\n",
    "scipy.io.savemat(handle, mdict=spec_dict, oned_as='row')\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "#what are we analyzing???? - this is the list of text analysis features\n",
    "infoDat = {}\n",
    "infoDat[1] = \"Number of Words\"\n",
    "infoDat[2] = \"Number of Sentences\"\n",
    "infoDat[3] = \"Frequency of Search Term\"\n",
    "infoDat[4] = \"Sentiment Analysis\"\n",
    "infoDat[5] = \"Subjectivity Analysis\"\n",
    "infoDat[6] = \"Grade level\"\n",
    "infoDat[7] = \"Flesch Reading Ease\"\n",
    "infoDat[8] = \"SMOG Index\"\n",
    "infoDat[9] = \"Coleman Liau\"\n",
    "infoDat[10] = \"Automated Readability Index\"\n",
    "infoDat[11] = \"Gunning Fog\"\n",
    "infoDat[12] = \"Dale Chall Readability Score\"\n",
    "infoDat[13] = \"Difficult Words\"\n",
    "infoDat[14] = \"Linsear Write Formula\"\n",
    "infoDat[15] = \"Text Standard\"\n",
    "\n",
    "#save these parameters for analysis purposes\n",
    "info_dict = { 'infoDat':infoDat}\n",
    "handle = 'Data/analysisInfo.mat'\n",
    "scipy.io.savemat(handle, mdict=info_dict, oned_as='row')\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "#set filePath below to specify where the data will be going after the code runs\n",
    "fileLocation = os.getcwd()\n",
    "\n",
    "if not os.path.exists(fileLocation):\n",
    "    os.makedirs(fileLocation)\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "#start all the analysis code\n",
    "\n",
    "#for s, value in enumerate(searchList):\n",
    "#def iter_over(searchListElement):\n",
    "sl = [ (i, val) for i, val in enumerate(searchList) ]\n",
    "for s, value in sl:\n",
    "    #s, value = searchListElement\n",
    "\n",
    "    if not os.path.exists(str(fileLocation) + '/' + str(value) +'/'):\n",
    "        os.makedirs(str(fileLocation) + '/' + str(value) +'/')\n",
    "    os.chdir(fileLocation +str('/') + str(value) +'/')\n",
    "\n",
    "    print (\" \")\n",
    "    print (\"###############################################\")\n",
    "    print (\" \")\n",
    "    print (\"Term {0} of {1} : {2}\".format(s+1 , str(len(searchList)), value))\n",
    "    print (\" \")\n",
    "    print (\"###############################################\")\n",
    "    #web = [ \"google_\",\"gScholar_\",\"bing_\",\"yahoo_\" ]\n",
    "    #web = [0:nweb]\n",
    "\n",
    "    for b in range(0,nweb):\n",
    "    #for b, _ in enumerate(web):\n",
    "        #search engine selection\n",
    "        if b == 0:\n",
    "            textName = \"google_\"\n",
    "            print (\"Google\")\n",
    "        elif b == 1:\n",
    "            textName = \"gScholar_\"\n",
    "            print (\"Google Scholar\")\n",
    "        elif b == 2:\n",
    "            textName = \"bing_\"\n",
    "            print (\"Bing\")\n",
    "        elif b == 3:\n",
    "            textName = \"yahoo_\"\n",
    "            print (\"Yahoo\")\n",
    "\n",
    "        #import pdb; pdb.set_trace()\n",
    "        #list_of_files = glob.glob(r'textName*.p')\n",
    "        list_of_files = sorted(glob.glob(str(textName)+r'*.p'))\n",
    "        #if len(list_of_files) >= 50:\n",
    "        list_of_files =  sorted(list_of_files[0:numURLs-1])\n",
    "\n",
    "        for p,fileName in enumerate(list_of_files):\n",
    "            print (\"-------------------------------------------\")\n",
    "            print (\"Analyzing Search Engine \" + str(b+1) + \" of \" + str(nweb) + \": Link \" + str(p)); print (\"\");\n",
    "            #open and read text q\n",
    "\n",
    "            #fileName = l#'{0}{1}.p'.format(textName,p+1)\n",
    "            print(fileName)\n",
    "            print(os.getcwd(), 'pwd')\n",
    "            import pickle\n",
    "\n",
    "            fileHandle = open(fileName, 'rb');\n",
    "            file_contents = pickle.load(fileHandle)\n",
    "            if len(file_contents) == 2:\n",
    "                date_created = file_contents[0]\n",
    "                url_text = file_contents[1]\n",
    "            else:\n",
    "\n",
    "                url_text = file_contents\n",
    "\n",
    "            #initialize dataArray Dictionary\n",
    "            urlDat = {}\n",
    "\n",
    "            ########################################################################\n",
    "            #remove unreadable characters\n",
    "            url_text = url_text.replace(\"-\", \" \") #remove characters that nltk can't read\n",
    "            textNum = re.findall(r'\\d', url_text) #locate numbers that nltk cannot see to analyze\n",
    "            for x in range(0,len(textNum)) :\n",
    "                url_text.find(textNum[x])\n",
    "\n",
    "            ########################################################################\n",
    "            ##Splitting text into:\n",
    "            #words.\n",
    "            URLtext = word_tokenize(url_text)\n",
    "            URLtext = [w.lower() for w in URLtext] #make everything lower case\n",
    "\n",
    "            urlDat[1] = textstat.lexicon_count(str(url_text))\n",
    "            #import pdb; pdb.set_trace()\n",
    "\n",
    "            #sentences\n",
    "            sents = sent_tokenize(url_text) #split all of text in to sentences\n",
    "            sents = [w.lower() for w in sents] #lowercase all\n",
    "\n",
    "            urlDat[2] = len(sents) #determine number of sentences\n",
    "\n",
    "            ########################################################################\n",
    "            ##frequency distribtuion of text\n",
    "            fdist = FreqDist(w.lower() for w in URLtext if w.isalpha()) #frequency distribution of words only\n",
    "\n",
    "            # Bug fix\n",
    "            # cast dict to list\n",
    "            fd_temp = list(fdist.items())\n",
    "\n",
    "            urlDat[3] = fdist[searchList[s].lower()] #frequency of search term\n",
    "\n",
    "            #frequency of all words\n",
    "            fAll = {}\n",
    "            for x in range(0,len(fd_temp)):\n",
    "                fAll[x,1], fAll[x,2] = [y.strip('}()\",{:') for y in (str(fd_temp[x])).split(',')]\n",
    "\n",
    "            #frequency of the most used n number of words\n",
    "            frexMost = fdist.most_common(15) #show N most common words\n",
    "            fM = {}\n",
    "            for x in range(0,len(frexMost)) :\n",
    "                fM[x,1], fM[x,2] = [y.strip('}()\",{:') for y in (str(frexMost[x])).split(',')]\n",
    "\n",
    "            ########################################################################\n",
    "            #Sentiment and Subjectivity analysis\n",
    "            testimonial = TextBlob(url_text)\n",
    "            testimonial.sentiment\n",
    "\n",
    "            urlDat[4] = testimonial.sentiment.polarity\n",
    "            urlDat[5] = testimonial.sentiment.subjectivity\n",
    "\n",
    "            ########################################################################\n",
    "            #determine syllable count for all words in each sentece\n",
    "            sentSyl = {}\n",
    "            WperS = {}\n",
    "            # for n,sent in enumerate(sents):\n",
    "            # future use\n",
    "            for n in range(0,len(sents)):\n",
    "\n",
    "                #setup sent variable to analyze each sentence individually\n",
    "                sent = sents[n] #select sentence n in total text\n",
    "                sent = word_tokenize(sent) #tokenize sentence n in to words\n",
    "                sent = [w.lower() for w in sent if w.isalpha()] #remove any non-text\n",
    "\n",
    "                WperS[n] = len(sent) #number of words per sentence\n",
    "\n",
    "                #syllable analysis\n",
    "\n",
    "                for x in range(0,len(sent)):\n",
    "                    word = sent[x]\n",
    "\n",
    "                    # Count the syllables in the word.\n",
    "                    syllables = textstat.syllable_count(str(word))\n",
    "                    sentSyl[n,x] = syllables\n",
    "            #\n",
    "            ########################################################################\n",
    "            ## Complexity Analysis\n",
    "            #try:\n",
    "            assert len(url_text) != 0\n",
    "            assert type(url_text) is not type(None)\n",
    "            urlDat[6]  = textstat.flesch_kincaid_grade(str(url_text))\n",
    "            urlDat[7] = textstat.flesch_reading_ease(str(url_text))\n",
    "            urlDat[8]  = textstat.smog_index(str(url_text))\n",
    "            urlDat[9]  = textstat.coleman_liau_index(str(url_text))\n",
    "            urlDat[10]  = textstat.automated_readability_index(str(url_text))\n",
    "            urlDat[11] = textstat.gunning_fog(str(url_text))\n",
    "\n",
    "            urlDat[12]  = textstat.dale_chall_readability_score(str(url_text))\n",
    "            urlDat[13]  = textstat.difficult_words(str(url_text))\n",
    "            urlDat[14]  = textstat.linsear_write_formula(str(url_text))\n",
    "            urlDat[15]  = textstat.text_standard(str(url_text))\n",
    "            #import pdb\n",
    "            #pdb.set_trace()\n",
    "\n",
    "            ########################################################################\n",
    "            ########################################################################\n",
    "            ########################################################################\n",
    "            ########################################################################\n",
    "            #clean-up and prep for saving for subsequent analysis and plotting\n",
    "\n",
    "            ##convert all dict variables to list for multidimensional conversion to matlab cell array\n",
    "            urlDat = list(urlDat.items())\n",
    "            sentSyl = list(sentSyl.items())\n",
    "            WperS = list(WperS.items())\n",
    "            fAll = list(fAll.items())\n",
    "            fM = list(fM.items())\n",
    "\n",
    "            ##generate a .mat file for further analysis in matlab\n",
    "            if b == 0 and p == 0:\n",
    "                obj_arr = [urlDat, WperS, sentSyl, fM, fAll]\n",
    "                #obj_arr = np.array([urlDat, WperS, sentSyl, fM, fAll], dtype=np.object)\n",
    "                print('dimensions change of object array: ',np.shape(obj_arr),np.shape(urlDat))\n",
    "                old = np.shape(obj_arr)\n",
    "\n",
    "            else:\n",
    "                obj_arr_add = [urlDat, WperS, sentSyl, fM, fAll]\n",
    "                #obj_arr_add = np.array([urlDat, WperS, sentSyl, fM, fAll], dtype=np.object)\n",
    "\n",
    "                print('dimensions change of object array: ',np.shape(obj_arr),np.shape(urlDat))\n",
    "\n",
    "                obj_arr = np.vstack( [obj_arr, obj_arr_add])\n",
    "                assert type(obj_arr) is not type(None)\n",
    "                assert np.shape(obj_arr) != old\n",
    "                old = np.shape(obj_arr)\n",
    "\n",
    "            handle = str('../Data/') + str(searchList[s]) + str('_term_')+ str(s)+ '.mat'\n",
    "            import scipy\n",
    "            scipy.io.savemat(handle, {'obj_arr':obj_arr} , oned_as='row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask.bag<from_se..., npartitions=1>\n",
      "<class 'dask.bag.core.Bag'>\n",
      " \n",
      "###############################################\n",
      " \n",
      "Term 1 of 1 : GMO\n",
      " \n",
      "###############################################\n",
      "Google\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 0\n",
      "\n",
      "google_0.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 1\n",
      "\n",
      "google_1.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 2\n",
      "\n",
      "google_10.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 3\n",
      "\n",
      "google_11.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 4\n",
      "\n",
      "google_12.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 5\n",
      "\n",
      "google_13.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 6\n",
      "\n",
      "google_14.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 7\n",
      "\n",
      "google_15.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 8\n",
      "\n",
      "google_16.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 9\n",
      "\n",
      "google_17.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 10\n",
      "\n",
      "google_18.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 11\n",
      "\n",
      "google_19.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 12\n",
      "\n",
      "google_2.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 13\n",
      "\n",
      "google_20.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 14\n",
      "\n",
      "google_21.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 15\n",
      "\n",
      "google_22.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 16\n",
      "\n",
      "google_23.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 17\n",
      "\n",
      "google_24.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 18\n",
      "\n",
      "google_25.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 19\n",
      "\n",
      "google_26.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 20\n",
      "\n",
      "google_27.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 21\n",
      "\n",
      "google_28.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 22\n",
      "\n",
      "google_29.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 23\n",
      "\n",
      "google_3.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 24\n",
      "\n",
      "google_30.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 25\n",
      "\n",
      "google_31.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 26\n",
      "\n",
      "google_32.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 27\n",
      "\n",
      "google_33.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 28\n",
      "\n",
      "google_34.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 29\n",
      "\n",
      "google_35.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 30\n",
      "\n",
      "google_36.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 31\n",
      "\n",
      "google_37.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 32\n",
      "\n",
      "google_38.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 33\n",
      "\n",
      "google_39.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "google_4.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 35\n",
      "\n",
      "google_40.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 36\n",
      "\n",
      "google_41.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 37\n",
      "\n",
      "google_42.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 38\n",
      "\n",
      "google_43.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 39\n",
      "\n",
      "google_44.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 40\n",
      "\n",
      "google_45.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 41\n",
      "\n",
      "google_46.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 42\n",
      "\n",
      "google_47.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 43\n",
      "\n",
      "google_48.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 44\n",
      "\n",
      "google_5.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 45\n",
      "\n",
      "google_6.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 46\n",
      "\n",
      "google_7.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 47\n",
      "\n",
      "google_8.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 1 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 48\n",
      "\n",
      "google_9.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "Google Scholar\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 0\n",
      "\n",
      "gScholar_0.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 1\n",
      "\n",
      "gScholar_1.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 2\n",
      "\n",
      "gScholar_10.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 3\n",
      "\n",
      "gScholar_11.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 4\n",
      "\n",
      "gScholar_12.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 5\n",
      "\n",
      "gScholar_13.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 6\n",
      "\n",
      "gScholar_14.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 7\n",
      "\n",
      "gScholar_15.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 8\n",
      "\n",
      "gScholar_16.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 9\n",
      "\n",
      "gScholar_17.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 10\n",
      "\n",
      "gScholar_18.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 11\n",
      "\n",
      "gScholar_19.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 12\n",
      "\n",
      "gScholar_2.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 13\n",
      "\n",
      "gScholar_20.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 14\n",
      "\n",
      "gScholar_21.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 15\n",
      "\n",
      "gScholar_22.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 16\n",
      "\n",
      "gScholar_23.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 17\n",
      "\n",
      "gScholar_24.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 18\n",
      "\n",
      "gScholar_25.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 19\n",
      "\n",
      "gScholar_26.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 20\n",
      "\n",
      "gScholar_27.p\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 21\n",
      "\n",
      "gScholar_28.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 22\n",
      "\n",
      "gScholar_29.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 23\n",
      "\n",
      "gScholar_3.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 24\n",
      "\n",
      "gScholar_30.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 25\n",
      "\n",
      "gScholar_31.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 26\n",
      "\n",
      "gScholar_32.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 27\n",
      "\n",
      "gScholar_33.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 28\n",
      "\n",
      "gScholar_34.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 29\n",
      "\n",
      "gScholar_35.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 30\n",
      "\n",
      "gScholar_36.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 31\n",
      "\n",
      "gScholar_37.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 32\n",
      "\n",
      "gScholar_38.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 33\n",
      "\n",
      "gScholar_39.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 34\n",
      "\n",
      "gScholar_4.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 35\n",
      "\n",
      "gScholar_40.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 36\n",
      "\n",
      "gScholar_41.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 37\n",
      "\n",
      "gScholar_42.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 38\n",
      "\n",
      "gScholar_43.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 39\n",
      "\n",
      "gScholar_44.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 40\n",
      "\n",
      "gScholar_45.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 41\n",
      "\n",
      "gScholar_46.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 42\n",
      "\n",
      "gScholar_47.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 43\n",
      "\n",
      "gScholar_48.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 44\n",
      "\n",
      "gScholar_5.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 45\n",
      "\n",
      "gScholar_6.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 46\n",
      "\n",
      "gScholar_7.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 47\n",
      "\n",
      "gScholar_8.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 2 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 48\n",
      "\n",
      "gScholar_9.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "Bing\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 0\n",
      "\n",
      "bing_0.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 1\n",
      "\n",
      "bing_1.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 2\n",
      "\n",
      "bing_10.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 3\n",
      "\n",
      "bing_11.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 4\n",
      "\n",
      "bing_12.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 5\n",
      "\n",
      "bing_13.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 6\n",
      "\n",
      "bing_14.p\n",
      "/home/jovyan/SReadability/GMO pwd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 7\n",
      "\n",
      "bing_15.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 8\n",
      "\n",
      "bing_16.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 9\n",
      "\n",
      "bing_17.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 10\n",
      "\n",
      "bing_18.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 11\n",
      "\n",
      "bing_19.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 12\n",
      "\n",
      "bing_2.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 13\n",
      "\n",
      "bing_20.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 14\n",
      "\n",
      "bing_21.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 15\n",
      "\n",
      "bing_22.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 16\n",
      "\n",
      "bing_23.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 17\n",
      "\n",
      "bing_24.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 18\n",
      "\n",
      "bing_25.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 19\n",
      "\n",
      "bing_26.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 20\n",
      "\n",
      "bing_3.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 21\n",
      "\n",
      "bing_4.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 22\n",
      "\n",
      "bing_5.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 23\n",
      "\n",
      "bing_6.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 24\n",
      "\n",
      "bing_7.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 25\n",
      "\n",
      "bing_8.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 3 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 26\n",
      "\n",
      "bing_9.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "Yahoo\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 4 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 0\n",
      "\n",
      "yahoo_0.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 4 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 1\n",
      "\n",
      "yahoo_1.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 4 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 2\n",
      "\n",
      "yahoo_10.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 4 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 3\n",
      "\n",
      "yahoo_11.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 4 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 4\n",
      "\n",
      "yahoo_12.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 4 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 5\n",
      "\n",
      "yahoo_2.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 4 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 6\n",
      "\n",
      "yahoo_3.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 4 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 7\n",
      "\n",
      "yahoo_4.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 4 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 8\n",
      "\n",
      "yahoo_5.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 4 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 9\n",
      "\n",
      "yahoo_6.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 4 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 10\n",
      "\n",
      "yahoo_7.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 4 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 11\n",
      "\n",
      "yahoo_8.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n",
      "-------------------------------------------\n",
      "Analyzing Search Engine 4 of ['google_', 'gScholar_', 'bing_', 'yahoo_']: Link 12\n",
      "\n",
      "yahoo_9.p\n",
      "/home/jovyan/SReadability/GMO pwd\n",
      "number of words is zero on that link, so analysis will fail\n"
     ]
    }
   ],
   "source": [
    "sl = [ (i, val) for i, val in enumerate(t_analysis.searchList) ]\n",
    "import dask.bag as db\n",
    "b = db.from_sequence(sl, npartitions=8)\n",
    "print(b)\n",
    "print(type(b))\n",
    "\n",
    "##\n",
    "#\n",
    "#\n",
    "\n",
    "obj_arrs = list(db.map(t_analysis.iter_over,b).compute())#.result()\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0  None"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=obj_arrs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df2 = df[0][1]\n",
    "#df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df.loc[0])\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib as plt\n",
    "plt.figure();\n",
    "df.iloc[0][3]\n",
    "#plt.plot(,kind='hist');\n",
    "'''\n",
    "for i in df.iloc[0][3]:\n",
    "    print(type(i[0]),type(i[1]))\n",
    "    print(i[0],i[1])#,i[2])\n",
    "'''    \n",
    "    #print(type(i[1]))\n",
    "#df.loc[0][3]\n",
    "#df.loc[0][4]\n",
    "#df.loc[0][5]\n",
    "#df.loc[0][6]\n",
    "len(obj_arrs[3])\n",
    "obj_arrs[0][3]\n",
    "obj_arrs[0][3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TermName = 'GMO'\n",
    "\n",
    "numVars = 13;\n",
    "word = len(TermName);\n",
    "\n",
    "web = 1#; %how many search engines\n",
    "numPerURL = 1#; %how many URLS per search engine\n",
    "crawlCount = 5#; %how many links are being crawled per URL\n",
    "\n",
    "\n",
    "#for wordi = 1:word\n",
    "for wordi in TermName:\n",
    "    print(wordi)\n",
    "    \n",
    "\n",
    "metricAvg = []\n",
    "metricAvg.append(8)#; %grade level\n",
    "metricAvg.append(65)#; %FK reading ease\n",
    "metricAvg.append(8)#; %FK grade level\n",
    "metricAvg.append(8)#; %Gunning Fog\n",
    "metricAvg.append(25.5)#; %SMOG\n",
    "metricAvg.append(8)#; %Coleman\n",
    "metricAvg.append(9)#; %Automated Readability Index\n",
    "'''\n",
    "    for webi = 1:web\n",
    "        for n = 1:7\n",
    "            %find min and max values for each metric\n",
    "            tempMin = min([plotData{webi,2}(n,:) metricAvg(n,1)]);\n",
    "            tempMax = max([plotData{webi,2}(n,:) metricAvg(n,1)]);\n",
    "\n",
    "            %normalize\n",
    "            for i = 1:numPerURL\n",
    "                NplotData{webi,2}(n,i) = (plotData{webi,2}(n,i) - tempMin)/(tempMax-tempMin);\n",
    "                metricAvg(n,2) = (metricAvg(n,1) - tempMin)/(tempMax-tempMin);\n",
    "            end; clear tempMin tempMax\n",
    "        end\n",
    "    end; clear webi n i\n",
    "\n",
    "    %save data for each keyword for later plot comparison\n",
    "    dataFinal{wordi,1} = DataFinal; clear DataFinal\n",
    "    MetricAvg{wordi,1} = metricAvg; clear metricAvg\n",
    "    PlotData{wordi,1} = plotData; clear plotData\n",
    "    normPlotData{wordi,1} = NplotData; clear NplotData\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
