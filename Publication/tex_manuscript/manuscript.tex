\documentclass{clv3}

\usepackage{hyperref}
\usepackage{xcolor}
\definecolor{darkblue}{rgb}{0, 0, 0.5}
\hypersetup{colorlinks=true,citecolor=darkblue, linkcolor=darkblue, urlcolor=darkblue}

\bibliographystyle{compling}

% test compatibility with algorithmic.sty
%\usepackage{algorithmic}

\issue{1}{1}{2016}

%Document Head
\dochead{Journal of Computational Linguistics}


\runningtitle{Science Accessibility Project}

\runningauthor{Russell J. Jarvis}

\begin{document}

\title{Science Accessibility Project}

\author{Russell J. Jarvis\thanks{Tempe, ASU. E-mail: rjjarvis@asu.edu.}}
\affil{School of Life Sciences ASU}

\author{Another Author\thanks{PITC Building}}
\affil{Publishing / SPi}

\author{And Another Author}
\affil{Publishing / SPi}

\author{And Yet Another}
\affil{Publishing / SPi}

\maketitle

\begin{abstract}
This article describes how we scrapped a wide variety of written word from the internet, and then analysed scrapped samples, in order to better charecterize the readability of scientific and non scientific writings.
\end{abstract}

\subsection{}keywords} 
Bag of words analysis, naive Bayes.

\section{Introduction}
# Science Accessibility Project
## Motivation for the Science Accessibility Project
Non-scientific writing typically exceeds genuine scientific writing in one important criteria: in contrast to genuine science non-science ideas are often expressed with a more accessible writing style. We believe non-science writing occupies a more accessible style niche, that academic science writing should also occupy. We show that we can use machine learning to predict the status of writing: popular culture writing, opinionative writing, and traditional science, by first scrapping a large variety of web documents, and then classifying among the different writing types. By predicting which of the several different writing types any writing piece occupies, we are able to characterize among different writing niches.\\
\\
Multiple stake holders can benefit when science is communicated with lower complexity expression of ideas. With lower complexity science writing, knowledge would be more readily transferred into public awareness, additionally, digital organization of facts derived from journal articles would occur more readily, as successful machine comprehension of documented science would likely occur with less human intervention.\\
\\
Objectively describing the different character of the different writing styles will allow us to prescribe how, to shift academic science writing into a more accessible niche, where science can more aggressively compete with pseudo-science, and blogs, facilitating greater knowledge transference, at a moment in history when public awareness is critically at stake.

## Machine Estimation of Writing Complexity.
The accessibility of written word can be approximated by a computer program that reads over the text, and guesses the mental difficulty, associated with comprehending a written document. The computer program maps reading difficult onto a quantity that represents the number of years of schooling needed to decode the language in the document. For convenience, we can refer to the difficulty associated with the text as the 'complexity' of the document. 


\section{Introduction Old}

Non-scientific writing typically exceeds genuine scientific writing in one important criteria: in contrast to genuine science non-science ideas are often expressed using a less complex more engaging writing style.  Yet, multiple stake holders could benefit if science was communicated using a less complex expression of ideas. Using less complicated science writing, knowledge could be more readily transferred into public awareness, also, and machine reading machine organization, and machine action on factual information derived from journal articles could occur more readily.

We believe non-science writing occupies a style niche, that academic science writing should also occupy. We show that we can blindly predict the status of writing: popular culture writing, opinionative writing, and traditional science, by using machine learning to classify the different writing types. By predicting which of the several different writing types any writing piece occupies, we are able to characterize among different writing niches.

Objectively describing the different character of the different writing styles will allow us to prescribe how, to shift academic science writing into a more accessible niche, where science can more aggressively compete with pseudo-science, and blogs, facilitating greater knowledge transference, at a moment in history when public awareness is critically at stake.


\section{Methods}

We built a web-scraping and written text analysis infrastructure by extending many existing Free and Open Source (FOS) tools. The Web scrapping interface employs several common python modules, chief among those was: Google Scrape, Beautiful Soup and Selenium. The Text analysis infrastructure was based on the two substantial code bases Text-stat, which contained measures of text reading level (complexity), and NLTK (the Natural Language Processing Tool Kit), which contained measures of text subjectivity, and sentiment type.

The scraping, and analysis work we performed, rested on top of a large hierarchy of software dependencies. However, it is increasingly well understood, that, dependency heavy software stacks act as a significant impediment to investigating or reproducing any product of digital, scholary research. In order to address this problem and to enhance the reproducibility of our approach, we created the necessary web-scrapping, and analysis infrastructure inside a dedicated Docker Container.

Reproducibility is burdened by the technical task of satisfying each software dependencies necessary to recreate a digital scientific experiment. Our position, of starting with from a cloned software environment, will mitigate, the burden of duplicating our digital research environment. That is why we have used a Docker file, and associated Docker container together, as they act as self-documenting and extremely portable software environment clone.

Initially we created two different, unrelated and broad ranging lists of scientific queries. The first type of query was predominantly cultural in nature, or world view related. The second set of queries represented gains in knowledge about physical entities or physical processes in the world. We were interested in scientific, and pseudo-scientific writing.\\

There were two types of writing that we actively excluded from our analysis, those were websites expressed in a non-English language, and also websites, that were highly commercial in nature. These were websites advertisements, of consumer goods, and online shopping generally. These websites, utilizing wording, that significantly biases text stat metrics. Webpages of less than 400 words, were most often advertisements, and websites of a comercial nature such as Amazon shopping.\\

Non English, websites were excluded for the simple reason that they are not amenable to Textstat, and NLTK tools, however, even if this was not the case, it is also known, that there are  significant differences in per-word information entropy between different natural languages.

\subsection{Search Engine Queries:}
The first two lists of queries were chosen to be belong to an overt set of exclusively scientific or cultural search terms. A third list of terms was designed to be deliberately ambiguous.

\subsubsection{Science Queries:}
The three lists of search engine queries were as implemented as follows: science engine queries: 'evolution', 'photo-sysnthesis' ,'Transgenic', 'GMO', 'climate change', 'cancer', 'Vaccines', 'Genetically Modified Organism', ‘differential equation’,"psycho-physics","soma”

\subsubsection{Cultural queries were as follows:} 'reality TV', 'prancercise philosophy', 'play dough delicious deserts', 'unicorn versus brumby', 'football soccer' , god fearing.

As discussed we also designed ambiguous queries which were equally likely return content that was either scientific, or non scientific in nature. The reason for doing this was to provide a challenge for the classification algorithm.

\subsubsection{Ambiguous Queries, were as follows:}

"the singularity","skynet","","killer robot","franken-science","Frankenstein,”the God Delusion","god does not play dice", "the selfish gene","political science", ", "requim for a spike"


After scraping across the two different lists were performed, the resulting queries were filtered, according to specific sets of criteria. As stated previously, we discarded from our analysis, web pages that were not written in English, since we did not have the necessary tools, to analyze them.

\subsection{Text Metrics:}
A list of metrics applied to downloaded corpus include: TextStat, which was used to measure word complexity (an average of several important word complexity metrics, such as the Gunning Fog measure of reading level), LZW compression-ratio, de-compression ratio, sentiment analysis, subjectivity analysis, and page rank.

Compression ratios were used to investigate the notion, that well written scientific writing, might simply be lower in information entropy, and an information theoretic analysis, can be used to both to better characterize, and corroborate the findings of other reading word complexity metrics

\subsection{Reference Texts:}

Some reference texts were used, as a means of providing contrast, and context, to data points, among our web scraping derived corpus. The Upgoer5 is a library, of scientific texts, written with the aid of a text editor, which imposes, that output documents are exclusively comprised by, only the 10,000 most commonly occurring English words.

The Post Modern Essay Generator (PMEG), embodies an artificial English synthesis technique. Documents that are output from the website, consist of sentences that obey the rules of written English, however there are no restraints governing the semantic conceptual references in the sentences. If any particular sentence in a PMEG document, embodies an objective meaning, it is only by chance. Output from PMEG reads as highly coded, and vague.

The reference data points in some ways provide further validation to the existing text metric tools, as we needed to verify that word readability metrics provided results that were consistant with prior assumptions about known texts. For instance, the corpus derived from upgoer editor, should require a very low reading grade level to understand. Texts, from the PMEG should require a very high reading level to understand, and cumulative entropy of such texts should be high.


\verb|\documentclass[bookreview,manuscript]{clv3}|

%\subsection{Default Option}

\begin{deflist}
\item[bookreview] Sets the article layout for Book Review.
\item[brief] Sets the article layout for Briefly Noted.
\item[discussion] Sets the article layout for Squibs and Discussions.
\item[pubrec] Sets the article layout for Publication Received.
\item[shortpaper] Sets the article layout for Short Paper.
\item[manuscript] Sets the baseline spacing to double space. This
option can be used in combination with other options.
\end{deflist}

By not declaring any option in the \verb|\documentclass| command the class file
will automatically set to standard article layout.

\section{Results}

We created a total list all of the different queries obtained, from combining both the list of cultural queries, and scientific queries, and then applied such queries exclusively to the Wikipedia, search interface. We take the result of evaluating this pool of queries, and then plot the resulting pool of queries versus page rank. The Wikipedia, actually showed a small but consistant preference for web pages of higher complexity.

%\begin{figure}
%	\centering
%	\includegraphics[width=0.7\linewidth]{screenshot001}
%	\caption{}
%	\label{fig:figure1}
%\end{figure}

%

The plots below may appear to look a bit unprofessional, as not all data points have error bars. The reason for this, is pandas+seaborne allows you to plot on the same axis multiple sample data points, and single sampled data points. Only of the five mentioned search engines was made to sample beyond page rank 10, but all five sampled under page rank 10.

%\begin{figure}
%	\centering
%	\includegraphics[width=0.7\linewidth, height=0.7\textheight]{figure2}
%	\caption{}
%	\label{fig:figure2}
%\end{figure}
%

The same plot but with mean and std deviation plots when multiple samples per page rank are available. When we plotted the Wikipedia queries, where reading (text-stat standard) level is instead plotted against page rank, we again see that there is a slight trend towards increasing text complexity with decreasing page rank. 


If instead we consider how resistant Wikipedia pages are to compression, we see that low page rank pages, are more resistant to compression. This finding recapitulates the same result as the above figure, where increasing Wikipedia page rank slightly decreases text complexity.

When aggregated search results between all possible search engines, and then plotting page rank versus complexity, for particular types of search terms, there was a strong positive correlation between page rank, and reading level.

In the case of GMO, and Genetically Modified Organism, positive increasing trends where observed

The title page is created using the standard \LaTeX\ command \verb|\maketitle|.
Before this command is declared, the author must declare all the data which are
to appear in the title area.\footnote{$\backslash$maketitle is the command to execute all the title page information.}

\subsection{Volume, Number and Year}

The command \verb|\issue{vv}{nn}{yyyy}| is used in declaring the volume, number
and year of the article. The first argument is for the volume, the second argument
is for the issue number. Volume and Issue number will appear on the even page
running head opposite the journal name. The third argument is for the Year which
will appear in the copyright line at the bottom of the title page.

\subsection{Document Head}

Document head is produced with the command \verb|\dochead{Document Head}|. Doc head
will output differently, or may not appear at all, depending on the option used in the
documentclass.

\subsection{Paper Title}

The paper title is declared like: \verb|\title{Computer Linguistic Article}|
in the usual \LaTeX manner. Line breaks may be inserted with (\verb|\\|) to equalize
the length of the title lines.

\subsection{Authors}
The name and related information for authors is declared with the \verb|\author{}| command.

The \verb|\thanks{}| command produces the ``first footnotes.''. \LaTeX\ \verb|\thanks|
cannot accommodate multiple paragraphs, author will have to use a separate \verb|\thanks|
for each paragraph.

The \verb|\affil{}| command produces the author affiliations that appears right under
the author's name.

\subsection{Running Headers}
The running heads are declared with the \verb|\runningtitle{Running Title}| for the
journal name and \verb|\runningauthor{Author's Surname}| for author. These information
will appear on the odd pages. For {\tt bookreview} option, odd page running head is
automatically set to "Book Reviews". Even page running head is default to Computational
Linguistics opposite volume and issue number.

\subsection{History Dates}

History dates are declared with \verb|\historydates{Submission received:...}|. This data
should contain Submission, Revised and Accepted date of the article. History dates appear
at the footnote area of title age.


\section{Abstract}

Abstract is the first part of a paper after \verb|\maketitle|. Abstract text is
placed within the abstract environment:

\begin{verbatim}
\begin{abstract}
This is the abstract text . . .
\end{abstract}
\end{verbatim}

\section{Section Headings}

Section headings are declared in the usual \LaTeX\ way via \verb|\section{}|,
\verb|\subsection{}|, \verb|\subsubsection{}|, and \verb|\paragraph{}|. The
first 3 levels of section head will have Arabic numbering separated
by period. The \verb|\paragraph{}| section will have the title head in Italics
and at the same line with the first line of succeeding paragraph.

\section{Citations}
Citations in parentheses are declared using the \verb|\cite{}|
command, and appear in the text as follows:
This technique is widely used \cite{woods}.
The command \verb|\citep{}| (cite parenthetical) is a synonym of \verb|\cite{}|.

Citations used in the sentence are declared using the \verb|\namecite{}|
commands, and appear in the text as follows:
\namecite{woods} first described this technique.
The command \verb|\citet{}| (cite textual) is a synonym of \verb|\namecite{}|.

This style file is designed to be used with the BibTeX
style file \verb|compling.bst|.  Include the command
\verb|\bibliographystyle{compling}| in your source file.

Citation commands are based on the \verb|natbib| package;
for details on options and further variants of the commands,
see the \verb|natbib| documentation.  In particular, options
exist to add extra text and page numbers.  For example,
\verb|\cite[cf.][ch.\ 1]{winograd}| yields: \cite[cf.][ch.\ 1]{winograd}.

The following examples illustrate how citations appear both in the text
and in the references section at the end of this document.
\begin{enumerate}
\item Article in journal:
 \namecite{akmajian};
 \namecite{woods}.
\item Book:
  \namecite{altenberg};
  \namecite{winograd}.
\item Article in edited collection/Chapter in book:
  \namecite{cutler};
  \namecite{sgall};
  \namecite{jurafsky}.
\item Technical report:
  \namecite{appelt};
  \namecite{robinson}.
\item Thesis or dissertation:
  \namecite{baart};
  \namecite{spaerckjones};
  \namecite{cahn}.
\item Unpublished item:
  \namecite{ayers}.
\item Conference proceedings:
  \namecite{benoit}.
\item Paper published in conference proceedings:
  \namecite{krahmer};
  \namecite{Copestake2001}.
\end{enumerate}


\section{Definition with Head}

Definition with head is declared by using the environment:
\\
\begin{verbatim}
\begin{definition}
Definition text. . .
\end{definition}
\end{verbatim}

This environment will generate the word {\bf ``Definition 1''} in bold on separate
line. The sequence number is generated for every definition environment. Definition
data will have no indention on the first line while succeeding lines will have hang
indention.

\section{Lists}

The usual \LaTeX\ itemize, enumerate and definition list environments are used
in CLV3 style.

To produce Numbered List use the environment:

\begin{verbatim}
\begin{enumerate}
\item First numbered list item
\item Second numbered list item
\item Third numbered list item
\end{enumerate}
\end{verbatim}

To produce Bulleted List use the environment:

\begin{verbatim}
\begin{itemize}
\item First bulleted list item
\item Second bulleted list item
\item Third bulleted list item
\end{itemize}
\end{verbatim}

To produce Definition List use the environment:

\begin{verbatim}
\begin{deflist}
\item[First]  Definition list item. . .
\item[Second] Definition list item. . .
\item[Third]  Definition list item. . .
\end{deflist}
\end{verbatim}

Additional list environment were also defined such as Unnumbered, Arabic and Alpha lists.

Unnumbered List is the list where item labels are not generated. To produce Unnumbered List use the environment:

\begin{verbatim}
\begin{unenumerate}
\item First list item
\item Second list item
\item Third list item
\end{unenumerate}
\end{verbatim}

To produce Arabic List use the environment:

\begin{verbatim}
\begin{arabiclist}
\item First arabic list item
\item Second arabic list item
\item Third arabic list item
\end{arabiclist}
\end{verbatim}

To produce Alpha List use the environment:

\begin{verbatim}
\begin{alphalist}
\item First alpha list item
\item Second alpha list item
\item Third alpha list item
\end{alphalist}
\end{verbatim}

All the list environments mentioned above can be nested with each other.

\subsection{Other List Types}

\subsubsection{Outline List or Example List}

\begin{verbatim}
\begin{exlist}
\item First outline list item. . .
\item Second outline list item. . .
\item Third outline list item. . .
\end{exlist}
\end{verbatim}

\subsubsection{Output Formula or Algorithm}

\begin{verbatim}
\begin{algorithm}
\item[Step 1] First item. . .
\item[Step 2] Second item. . .
\end{algorithm}
\end{verbatim}

% test compatibility with algorithmic.sty
%\begin{algorithmic}
%\STATE i
%\end{algorithmic}

See sample on the {\tt COLI-template.pdf}.

\section{Word Formula or Displayed Text}

Word formula and displayed text are text that should be displayed in a
separate line without indention. This are achieved by using the environment:

\begin{verbatim}
\begin{displaytext}
This is a sample of displayed text . . .
\end{displaytext}
\end{verbatim}

\section{Dialogue}

Dialogue text are presentation of people's conversation. These will be presented
on a separate line where each dialogue starts with the name of speaker, followed by
colon. Succeeding lines will be hang indented. To produce Dialogue use the environment:
\\
\begin{verbatim}
\begin{dialogue}
Speaker 1: dialogue. . .

Speaker 2: dialogue. . .
\end{dialogue}
\end{verbatim}


\noindent Please make sure to insert an empty line between dialogues.

\section{Extracts}

Extract text acts like quote, where left and right margins are indented.
To produce Extract use the environment:

\begin{verbatim}
\begin{extract}
This is an example of Extract text. . .
\end{extract}
\end{verbatim}

\noindent See sample on the {\tt COLI-template.pdf}.

\section{Theorem-like Environments}

There are several theorem-like environments defined in CLV3 class file. Theorem-like
environments generate the name of the theorem as label, and counter number in bold.

\subsection{Example}

To produce Example use the environment:

\begin{verbatim}
\begin{example}
This is Example text. . .
\end{example}
\end{verbatim}

\subsection{Lemma}

To produce Lemma use the environment:

\begin{verbatim}
\begin{lemma}
Lemma text. . .
\end{lemma}
\end{verbatim}

This produces the following output:
\begin{lemma}\label{lem}
Lemma text.
\end{lemma}
A small vertical space separates the end of the lemma
from the following text.

\subsection{Theorem}

To produce Theorem use the environment:

\begin{verbatim}
\begin{theorem}
Theorem text. . .
\end{theorem}
\end{verbatim}

This produces the following output:
\begin{theorem}\label{thm}
Theorem text.
\end{theorem}
\noindent
A small vertical space separates the end of the theorem
from the following text.

\subsection{Proof}

The proof environment produces a square at the end of the text. To produce Proof
use the environment:

\begin{verbatim}
\begin{proof}
Proof text. . .
\end{proof}
\end{verbatim}

This produces the following output:
\begin{proof}\label{proof}
Proof text.
\end{proof}
A small vertical space separates the end of the lemma
from the following text.

\subsection{Unnumbered Theorem-like Environments}

There are also unnumbered version of some of the theorem-like environments.
These are declared by using its asterisked version. Here are the three
unnumbered version of theorem-like environments:

\begin{verbatim}
\begin{theorem*}
Unnumbered theorem text. . .
\end{theorem*}
\end{verbatim}

\section{Appendix}

Appendix is declared by issuing the command \verb|\appendix|. This will set
the necessary labels to appendix's rule (i.e. (A.1) for equation number).

Sections inside Appendix are declared using \verb|\appendixsection{}|, which
will produce {\bf Appendix A: Section Title} for first section.

Equation numbers are automatically set to (A.1), (A.2) and (A.3). Where the letters
follow the current level of Appendix section. So equations on {\bf Appendix B}
will have equation numbers as follow: (B.1), (B.2) and (B.3).

\section{Acknowledgments}

Acknowledgments are produce by using the environment:
\\
\begin{verbatim}
\begin{acknowledgments}
Acknowledgments text. . .
\end{acknowledgments}
\end{verbatim}

\section{Others}

Other items such as Equations, Figures, Tables and References are produced in
the standard \LaTeX\ typesetting.

\starttwocolumn
\bibliography{compling_style}

\end{document}
